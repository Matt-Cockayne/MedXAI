{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "093e6642",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Import explainability toolkit\n",
    "from explainers import GradCAM, GradCAMPlusPlus, IntegratedGradients\n",
    "from utils import load_model, get_target_layer_name, load_image, compare_methods\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3becfe0",
   "metadata": {},
   "source": [
    "## Load Model\n",
    "\n",
    "Load a pre-trained model from torchvision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e07b528",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ResNet50\n",
    "model = load_model('resnet50', pretrained=True, device=device)\n",
    "target_layer = get_target_layer_name(model)\n",
    "\n",
    "print(f\"Model loaded: ResNet50\")\n",
    "print(f\"Target layer for GradCAM: {target_layer}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede2260c",
   "metadata": {},
   "source": [
    "## Load Image\n",
    "\n",
    "Load and preprocess an image for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6789797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load image - update this path!\n",
    "image_path = 'path/to/your/image.jpg'\n",
    "image = load_image(image_path)\n",
    "\n",
    "# Display image\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.imshow(image.permute(1, 2, 0))\n",
    "plt.axis('off')\n",
    "plt.title('Input Image')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cc55088",
   "metadata": {},
   "source": [
    "## Get Prediction\n",
    "\n",
    "Get the model's prediction for the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f46db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input\n",
    "input_tensor = image.unsqueeze(0).to(device)\n",
    "\n",
    "# Get prediction\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "    probs = torch.nn.functional.softmax(output, dim=1)\n",
    "    top5_probs, top5_indices = torch.topk(probs[0], 5)\n",
    "\n",
    "# Display results\n",
    "print(\"Top 5 Predictions:\")\n",
    "for i, (prob, idx) in enumerate(zip(top5_probs, top5_indices)):\n",
    "    print(f\"  {i+1}. Class {idx}: {prob:.4f}\")\n",
    "\n",
    "target_class = int(top5_indices[0])\n",
    "print(f\"\\nTarget class for explanation: {target_class}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def144c1",
   "metadata": {},
   "source": [
    "## Generate Explanations\n",
    "\n",
    "Generate explanations using different methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67234042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize explainers\n",
    "explainers = {\n",
    "    'GradCAM': GradCAM(model, target_layer, device),\n",
    "    'GradCAM++': GradCAMPlusPlus(model, target_layer, device),\n",
    "    'Integrated Gradients': IntegratedGradients(model, device)\n",
    "}\n",
    "\n",
    "# Generate explanations\n",
    "explanations = {}\n",
    "for method_name, explainer in explainers.items():\n",
    "    print(f\"Generating {method_name}...\")\n",
    "    explanation = explainer.explain(input_tensor, target_class)\n",
    "    explanations[method_name] = explanation\n",
    "\n",
    "print(\"âœ… All explanations generated!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014c9756",
   "metadata": {},
   "source": [
    "## Visualize Comparisons\n",
    "\n",
    "Compare the different explanation methods side-by-side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c41011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison visualization\n",
    "fig = compare_methods(\n",
    "    image,\n",
    "    explanations,\n",
    "    colormap='jet',\n",
    "    figsize=(15, 4)\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1012f",
   "metadata": {},
   "source": [
    "## Individual Explanations\n",
    "\n",
    "View each explanation in detail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c02e661",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import overlay_heatmap\n",
    "\n",
    "for method_name, heatmap in explanations.items():\n",
    "    # Create overlay\n",
    "    overlaid = overlay_heatmap(image, heatmap, alpha=0.5)\n",
    "    \n",
    "    # Display\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    \n",
    "    # Show heatmap\n",
    "    ax1.imshow(heatmap, cmap='jet')\n",
    "    ax1.set_title(f'{method_name} - Heatmap')\n",
    "    ax1.axis('off')\n",
    "    \n",
    "    # Show overlay\n",
    "    ax2.imshow(overlaid)\n",
    "    ax2.set_title(f'{method_name} - Overlay')\n",
    "    ax2.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ead712ee",
   "metadata": {},
   "source": [
    "## Quantitative Evaluation\n",
    "\n",
    "Evaluate explanations using deletion and insertion metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa47b833",
   "metadata": {},
   "outputs": [],
   "source": [
    "from metrics import DeletionInsertion\n",
    "\n",
    "# Initialize metric\n",
    "di_metric = DeletionInsertion(model, device, n_steps=50)\n",
    "\n",
    "# Evaluate each method\n",
    "results = {}\n",
    "for method_name, heatmap in explanations.items():\n",
    "    print(f\"Evaluating {method_name}...\")\n",
    "    result = di_metric.evaluate(input_tensor, heatmap, target_class)\n",
    "    results[method_name] = result\n",
    "    print(f\"  Deletion AUC: {result['deletion_auc']:.3f}\")\n",
    "    print(f\"  Insertion AUC: {result['insertion_auc']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db10419a",
   "metadata": {},
   "source": [
    "## Plot Evaluation Curves\n",
    "\n",
    "Visualize the deletion and insertion curves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c83056e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import plot_deletion_insertion_curves\n",
    "\n",
    "fig = plot_deletion_insertion_curves(results, figsize=(15, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f377b31",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "Compare all methods based on their metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "316c4199",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create summary table\n",
    "summary_data = []\n",
    "for method_name, result in results.items():\n",
    "    summary_data.append({\n",
    "        'Method': method_name,\n",
    "        'Deletion AUC': f\"{result['deletion_auc']:.3f}\",\n",
    "        'Insertion AUC': f\"{result['insertion_auc']:.3f}\"\n",
    "    })\n",
    "\n",
    "df = pd.DataFrame(summary_data)\n",
    "print(\"\\nSummary of Results:\")\n",
    "print(df.to_string(index=False))\n",
    "\n",
    "print(\"\\nðŸ“Š Interpretation:\")\n",
    "print(\"  â€¢ Deletion AUC: Lower is better (explanation captures important features)\")\n",
    "print(\"  â€¢ Insertion AUC: Higher is better (explanation is sufficient for prediction)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80eec624",
   "metadata": {},
   "source": [
    "## Next Steps\n",
    "\n",
    "- Try different models (ResNet18, DenseNet, EfficientNet)\n",
    "- Experiment with medical imaging datasets\n",
    "- Add ground truth masks for plausibility evaluation\n",
    "- Test perturbation-based methods (RISE, Occlusion)\n",
    "- Explore attention-based methods for Vision Transformers"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
